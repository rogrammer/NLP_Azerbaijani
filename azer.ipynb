{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.text import Text\n",
    "from polyglot.detect import Detector\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file with pandas library\n",
    "datatext = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values\n",
    "datatext.dropna(inplace=True)\n",
    "datatext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all letters of text to lowercase\n",
    "datatext['content'] = datatext['content'].str.lower()\n",
    "datatext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = datatext['score'].value_counts().sort_index()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram\n",
    "plt.bar(scores.index, scores, color='blue', alpha=0.7, width=0.7)\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sentiment Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upvotes = datatext['upvotes'].value_counts().sort_index()\n",
    "upvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(upvotes.index, upvotes, color='green', alpha=0.7, width=2)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Upvote Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Upvote Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "def preprocessor(text):\n",
    "#   for word in Text(text).words:\n",
    "#   if Detector(word).language.code != 'az':\n",
    "#      re.sub(word, '', text)\n",
    "#     print(word)\n",
    "    \n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "datatext['content'] = datatext['content'].apply(preprocessor)\n",
    "datatext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to train and test sets\n",
    "split_point = int(len(datatext) * 0.8)\n",
    "train, test = datatext[ : split_point], datatext[split_point : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poly = []\n",
    "all_spacy = []\n",
    "all_nltk = []\n",
    "\n",
    "# Load the spaCy EN language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "for sentence in train['content']:\n",
    "    sentence = str(sentence)\n",
    "    \n",
    "    # Polyglot Tokenization\n",
    "    polyglot_text = Text(sentence)\n",
    "    polyglot_tokens = [word for word in polyglot_text.words]\n",
    "    all_poly.append(polyglot_tokens)\n",
    "\n",
    "    # NLTK Tokenization\n",
    "    nltk_tokens = nltk.word_tokenize(sentence)\n",
    "    all_nltk.append(nltk_tokens)\n",
    "\n",
    "    # spaCy Tokenization\n",
    "    spacy_doc = nlp(sentence)\n",
    "    spacy_tokens = [token.text for token in spacy_doc]\n",
    "    all_spacy.append(spacy_tokens)\n",
    "\n",
    "    # Comparing the results\n",
    "    \"\"\" print(\"Comparison:\")\n",
    "    print(\"Polyglot has\", len(polyglot_tokens), \"tokens:\", polyglot_tokens)\n",
    "    print(\"NLTK has\", len(nltk_tokens), \"tokens:\", nltk_tokens)\n",
    "    print(\"spaCy has\", len(spacy_tokens), \"tokens:\", spacy_tokens) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
